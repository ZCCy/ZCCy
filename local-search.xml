<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>K邻近算法（K-Nearest Neighbors）</title>
    <link href="/2022/08/13/K-Nearest%20Neighbors/"/>
    <url>/2022/08/13/K-Nearest%20Neighbors/</url>
    
    <content type="html"><![CDATA[<h1 id="k邻近算法k-nearest-neighbors">K邻近算法（K-NearestNeighbors）</h1><h2 id="一理论学习">一、理论学习：</h2><p>当我们想知道路边一朵特别好看的野花名字的时候，我们可以用百度的图片搜索，将当前这一朵野花与搜出来的许多结果进行对比，然后选择了和它长得最像的一朵，将这一朵花和路边遇到的视为同一朵花，然后再由网上的结果来确定路边这一朵花的品种。</p><p>这样一个确定花品种的过程也就是KNN算法“学习”的过程。网上搜出来的许多花也就是KNN算法预先拥有的样本，路边遇到的野花就是本次要分类的对象，通过计算本次对象与KNN所拥有的样本之间的“距离”，来确定它所处的分类：</p><p><img src="https://cdn.jsdelivr.net/gh/ZCCy/Blog-Picture@master/uPic/KNN_Test.png" alt="KNN_Test" style="zoom:67%;" /></p><h2 id="二实践">二、实践：</h2><h3 id="实验过程">实验过程：</h3><ul><li><h4 id="数据集">数据集：</h4><p>该数据集同样描述描述的是一位顾客在年龄和预算的两个条件下是否会购买该商品</p><p><img src="https://cdn.jsdelivr.net/gh/ZCCy/Blog-Picture@master/uPic/2HDPb4.png" alt="EpBzio" style="zoom: 40%;" /></p></li><li><h4 id="测试结果">测试结果：</h4><p><img src="https://cdn.jsdelivr.net/gh/ZCCy/Blog-Picture@master/uPic/KNN_result.png" alt="KNN_result" style="zoom:80%;" /></p></li></ul><h3 id="代码实现">代码实现：</h3><ul><li><h4 id="数据处理">数据处理：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset = pd.read_csv(<span class="hljs-string">&#x27;datasets/Social_Network_Ads.csv&#x27;</span>)<br>X = dataset.iloc[:, [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]].values<br>y = dataset.iloc[:, <span class="hljs-number">4</span>].values<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.25</span>, random_state=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure></li><li><h4 id="对数据进行标准化和归一化">对数据进行标准化和归一化：</h4><p><strong>fit</strong>：原义指的是安装、使适合的意思，其实有点train的含义但是和train不同的是，它并不是一个训练的过程，而是一个适配的过程，过程都是定死的，最后只是得到了一个统一的转换的规则模型。<strong>transform</strong>：是将数据进行转换，比如数据的归一化和标准化，将测试数据按照训练数据同样的模型进行转换，得到特征向量。<strong>fit_transform</strong>：可以看做是fit和transform的结合，如果训练阶段使用fit_transform，则在测试阶段只需要对测试样本进行transform就行了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">sc = StandardScaler()<br>X_train = sc.fit_transform(X_train)<br>X_test = sc.transform(X_test)<br></code></pre></td></tr></table></figure></li><li><h4id="使用k-nn对训练集数据进行训练">使用K-NN对训练集数据进行训练：</h4><p>由于实现逻辑比较简单，所以这里就直接使用了sklearn中的学习器</p><p>参数说明：<code>n_neighbors</code>就是指的k值，<code>metric</code>时用于树的距离度量。默认度量是<code>minkowski</code>，<code>p=2</code>等价于标准的欧几里德度量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">classifier = KNeighborsClassifier(n_neighbors=<span class="hljs-number">5</span>, metric=<span class="hljs-string">&#x27;minkowski&#x27;</span>, p=<span class="hljs-number">2</span>)<br>classifier.fit(X_train, y_train)<br></code></pre></td></tr></table></figure></li><li><h4 id="对测试集进行预测">对测试集进行预测:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">y_pred = classifier.predict(X_test)<br></code></pre></td></tr></table></figure></li></ul><h2 id="三总结">三、总结：</h2><p>本次实验只是探索了在二维数据的情况下，KNN算法的处理方式，但是当面对高维问题的时候我们就需要进行降维处理，这个将在以后的过程中展开。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>逻辑回归（logistics-regression）</title>
    <link href="/2022/08/09/logistics-regression/"/>
    <url>/2022/08/09/logistics-regression/</url>
    
    <content type="html"><![CDATA[<h1 id="逻辑回归logistics-regression">逻辑回归（logisticsregression）</h1><h2 id="一理论学习">一、理论学习：</h2><p><strong>线性回归模型</strong>可得到：$ y =^Tx+b $，这个模型可以很好的符合当<strong>输入值</strong>（也就是x，条件值）和<strong>输出值</strong>（也就是y，预测值）为<strong>线性函数关系</strong>的时候。那么当<spanclass="math inline">\(x\)</span> 和<spanclass="math inline">\(y\)</span>不再是线性函数映射的时候，线性回归模型的<spanclass="math inline">\(plus\)</span>版：<strong>广义线性模型</strong>：<spanclass="math inline">\(y=g^{-1}(\omega^T+b)\)</span>也可以将<spanclass="math inline">\(x\)</span>和<spanclass="math inline">\(y\)</span>联系起来，其中<spanclass="math inline">\(g^{-1}(·)\)</span>就是<spanclass="math inline">\(x\)</span>和<spanclass="math inline">\(y\)</span>对应的函数映射。例如本次要探究的<strong>对数几率回归模型</strong>。</p><p>对数几率回归模型的主要应用在各种<strong>二分类</strong>的问题里，在二分类问题里，预测值的值域是<spanclass="math inline">\(\{0,1\}\)</span>。要将线性的输入值投射到的<spanclass="math inline">\(\{0,1\}\)</span>值域区间内，就需要找到一个函数，可以将<spanclass="math inline">\(z\)</span>投射到<spanclass="math inline">\(\{0,1\}\)</span>的的值域内。这样最理想的函数便是接近<strong>单位阶级跃函数</strong>的一个替代函数：<span class="math display">\[y=\frac{1}{1+e^{-z}}\]</span><img src="https://cdn.jsdelivr.net/gh/ZCCy/Blog-Picture@master/uPic/对数几率函数.png" alt="Logistic_Regression_Sigmoid" style="zoom: 20%;" /></p><p>由图可以看到：该函数可以近似为一个单位阶级跃函数： <spanclass="math display">\[\begin{eqnarray}\end{eqnarray}y=\left\{\begin{array}{cc}0, &amp; z&lt;0 \\0.5, &amp; z=0 \\1, &amp; z&gt;0。\end{array}\right.\]</span> 当我们得到了在二分类中的<spanclass="math inline">\(x\)</span>和<spanclass="math inline">\(y\)</span>对应的函数映射，将输入值的线性表达带入<spanclass="math inline">\(y=\frac{1}{1+e^{-z}}\)</span>中，便可以得到对数几率回归的模型：<span class="math display">\[h=\frac{1}{1+e^{-(\omega ^Tx+b)}}\]</span></p><p>通过极大似然法（maximum likelihoodmethod），来估计要训练的参数：<spanclass="math inline">\(\omega,b\)</span> <span class="math display">\[L(\omega,b)=\prod_{i=1}^{m} P\left(y_{i} \mid x_{i} ;\omega,b\right)=\prod_{i=1}^{m}\left(h_{\omega,b}\left(x_{i}\right)\right)^{y_{i}}\left(1-h_{\omega,b}\left(x_{i}\right)\right)^{1-y_{i}}\]</span> 接着通过梯度下降法，求出参数<spanclass="math inline">\(\omega,b\)</span>的更新公式： <spanclass="math display">\[\begin{array}{l}\omega_j \leftarrow \omega_j-\alpha \frac{1}{m} {\textstyle\sum_{i=1}^{m}} (h(x_i)-y_i)x_i^j \\b_j \leftarrow b_j-\alpha\frac{1}{m}{\textstyle\sum_{i=1}^{m}}(h(x_i)-y_i)\end{array}\]</span></p><h2 id="二实践">二、实践：</h2><ul><li><p>数据集：该数据集描述的是一位顾客在年龄和预算的两个条件下是否会购买该商品</p><p><img src="https://cdn.jsdelivr.net/gh/ZCCy/Blog-Picture@master/uPic/2HDPb4.png" alt="Logistic_Regression_Dataset" style="zoom: 40%;" /></p></li><li><p>测试结果：</p><p><img src="https://cdn.jsdelivr.net/gh/ZCCy/Blog-Picture@master/uPic/Logistic_Regression_Result.png" alt="Logistic_Regression_Result" style="zoom:67%;" /></p></li></ul><p>具体会用到的包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><span class="hljs-keyword">import</span> logistic_regression_mine<br><span class="hljs-keyword">from</span> matplotlib.colors <span class="hljs-keyword">import</span> ListedColormap<br></code></pre></td></tr></table></figure><h4 id="数据归一化与标准化">1、数据归一化与标准化：</h4><ul><li><p>计算训练集的平均值和标准差，以便测试数据集使用相同的变换。一般情况下，在监督学习中，我们需要利用训练集数据对测试集数据进行预测。这里隐含了一个假设，就是训练数据和测试数据实际上是同分布的（因此我们才可以使用训练数据集来预测测试数据集），来自于同一个总体。在进行标准化的过程中就将训练集的均值和方差当做是总体的均值和方差，因此对测试集使用训练集的均值和方差进行预处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">ataset = pd.read_csv(<span class="hljs-string">&#x27;datasets/Social_Network_Ads.csv&#x27;</span>)<br><span class="hljs-comment"># iloc[a:b,c:d]:取行索引从a到b-1，列索引从c到d-1的数据。</span><br><span class="hljs-comment"># iloc[a:b,[c,d]]]:取行索引从a到b-1，列索引从c到d的数据。</span><br><span class="hljs-comment"># iloc[].values，用values属性取值，返回ndarray，但是单个数值无法用values函数读取。</span><br>X = dataset.iloc[:, [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]].values  <span class="hljs-comment"># 取年龄和薪资两列</span><br>y = dataset.iloc[:, <span class="hljs-number">4</span>].values  <span class="hljs-comment"># 取出结果（是否购买）</span><br><span class="hljs-comment"># 分割训练集和测试集</span><br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.25</span>, random_state=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>关于归一化前后的数据对比：</p><ul><li><p>归一化之前：</p><p><img src="https://cdn.jsdelivr.net/gh/ZCCy/Blog-Picture@master/uPic/Normalized-befor.png" alt="Normalized-befor" style="zoom:33%;" /></p></li><li><p>归一化之后：</p><p><img src="https://cdn.jsdelivr.net/gh/ZCCy/Blog-Picture@master/uPic/Normalized-after.png" alt="Normalized-after" style="zoom:33%;" /></p></li></ul></li></ul><h4 id="使用训练集训练并预测">2、使用训练集训练并预测：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">classifier = LogisticRegression()<br>classifier.fit(X_train, y_train)<br>clf = logistic_regression_mine.LogisticRegressionMine(learning_rate=<span class="hljs-number">0.1</span>, max_iter=<span class="hljs-number">500</span>, seed=<span class="hljs-number">272</span>)<br>clf.fit(X_train, y_train)<br>y_pred = clf.predict(X_test)<br></code></pre></td></tr></table></figure><h4 id="图形化处理">3、图形化处理：</h4><ul><li><p>生成可视化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">X_set, y_set = X_test, y_test<br>X1, X2 = np. meshgrid(np. arange(start=X_set[:, <span class="hljs-number">0</span>].<span class="hljs-built_in">min</span>()-<span class="hljs-number">1</span>, stop=X_set[:, <span class="hljs-number">0</span>].<span class="hljs-built_in">max</span>()+<span class="hljs-number">1</span>, step=<span class="hljs-number">0.01</span>),np. arange(start=X_set[:, <span class="hljs-number">1</span>].<span class="hljs-built_in">min</span>()-<span class="hljs-number">1</span>, stop=X_set[:, <span class="hljs-number">1</span>].<span class="hljs-built_in">max</span>()+<span class="hljs-number">1</span>, step=<span class="hljs-number">0.01</span>))<br>plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),<br>             alpha=<span class="hljs-number">0.75</span>, cmap=ListedColormap((<span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;green&#x27;</span>)))<br>plt.xlim(X1.<span class="hljs-built_in">min</span>(), X1.<span class="hljs-built_in">max</span>())<br>plt.ylim(X2.<span class="hljs-built_in">min</span>(), X2.<span class="hljs-built_in">max</span>())<br><span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(np. unique(y_set)):<br>    plt.scatter(X_set[y_set == j, <span class="hljs-number">0</span>], X_set[y_set == j, <span class="hljs-number">1</span>],<br>                c=ListedColormap((<span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;green&#x27;</span>))(i), label=j)<br>plt. title(<span class="hljs-string">&#x27; LOGISTIC(Test set)&#x27;</span>)<br>plt. xlabel(<span class="hljs-string">&#x27; Age&#x27;</span>)<br>plt. ylabel(<span class="hljs-string">&#x27; Estimated Salary&#x27;</span>)<br>plt. legend()<br>plt. show()<br></code></pre></td></tr></table></figure></li></ul><h4 id="逻辑回归实现类">4、逻辑回归实现类：</h4><ul><li><p>调用接口与初始化函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LogisticRegressionMine</span>(<span class="hljs-title class_ inherited__">object</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, learning_rate=<span class="hljs-number">0.1</span>, max_iter=<span class="hljs-number">100</span>, seed=<span class="hljs-literal">None</span></span>):<br>        self.seed = seed<br>        self.lr = learning_rate<br>        self.max_iter = max_iter<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, x, y</span>):<br>        np.random.seed(self.seed)<br>        self.w = np.random.normal(loc=<span class="hljs-number">0.0</span>, scale=<span class="hljs-number">1.0</span>, size=x.shape[<span class="hljs-number">1</span>])<br>        self.b = np.random.normal(loc=<span class="hljs-number">0.0</span>, scale=<span class="hljs-number">1.0</span>)<br>        self.x = x<br>        self.y = y<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.max_iter):<br>            self._update_step()<br>            <span class="hljs-comment"># print(&#x27;loss: \t&#123;&#125;&#x27;.format(self.loss()))</span><br>            <span class="hljs-comment"># print(&#x27;score: \t&#123;&#125;&#x27;.format(self.score()))</span><br>            <span class="hljs-comment"># print(&#x27;w: \t&#123;&#125;&#x27;.format(self.w))</span><br>            <span class="hljs-comment"># print(&#x27;b: \t&#123;&#125;&#x27;.format(self.b))</span><br></code></pre></td></tr></table></figure></li><li><p>定义sigmoid函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#定义sigmoid函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">self,z</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1.0</span> / (<span class="hljs-number">1</span> + np.exp(-z))<br></code></pre></td></tr></table></figure></li><li><p>将线性实值投射到sigmoid函数上，并计算预测值:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">self, x, w, b</span>):<br>    z = x.dot(w) + b<br>    <span class="hljs-keyword">return</span> self.sigmoid(z)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_proba</span>(<span class="hljs-params">self, x=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">if</span> x <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        x = self.x<br>    y_pred = self._f(x, self.w, self.b)<br>    <span class="hljs-keyword">return</span> y_pred<br><span class="hljs-comment"># 将实值x计算sigmoid的1，0值</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, x=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">if</span> x <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        x = self.x<br>    y_pred_proba = self.f(x, self.w, self.b)<br>    y_pred = np.array([<span class="hljs-number">0</span> <span class="hljs-keyword">if</span> y_pred_proba[i] &lt; <span class="hljs-number">0.5</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_pred_proba))])<br>    <span class="hljs-keyword">return</span> y_pred<br></code></pre></td></tr></table></figure></li><li><p>更新参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_calc_gradient</span>(<span class="hljs-params">self</span>):<br>    y_pred = self.predict()<br>    d_w = (y_pred - self.y).dot(self.x) / <span class="hljs-built_in">len</span>(self.y)<br>    d_b = np.mean(y_pred - self.y)<br>    <span class="hljs-keyword">return</span> d_w, d_b<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_update_step</span>(<span class="hljs-params">self</span>):<br>    d_w, d_b = self._calc_gradient()<br>    self.w = self.w - self.lr * d_w<br>    self.b = self.b - self.lr * d_b<br>    <span class="hljs-keyword">return</span> self.w, self.b<br></code></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <categories>
      
      <category>机器学习基础实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>回归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>操作系统学习（一）：启动 _</title>
    <link href="/2022/08/01/SystemStart/"/>
    <url>/2022/08/01/SystemStart/</url>
    
    <content type="html"><![CDATA[<h4 id="打开电源-cpu初始化bios引导">0、打开电源CPU初始化（BIOS引导)</h4><ul><li>加点之后寄存器开始做一些初始化的工作，将CS=0xFFFF，IP=0X0000，于是CPU转去执行0XFFFF0处的指令，这里是一个指向BIOS程序的入口的转跳指令。</li></ul><h4 id="bios启动">1、BIOS启动：</h4><ul><li>PownOn：校验CMOS（CMOS指保存计算机基本启动信息（如日期、时间、启动设置等）的芯片。CMOS是主板上的一块可读写的并行或串行FLASH芯片，是用来保存<ahref="https://baike.baidu.com/item/BIOS">BIOS</a>的硬件配置和用户对某些参数的设定。）是否正常，检验一些硬件状态。</li><li>POST：检查现存，显卡，内存测试。然后进行分配中断、IO端口、DMA资源等，这个时候会建立一个中断向量表和中断服务程序主要用于用户进行键盘和鼠标操作。</li><li>退出：MBR启动盘再第一扇区占512字节，以0XAA55结束，将启动盘程序复制到物理内存0x7C00处。</li></ul><h4 id="boot引导程序">2、boot引导程序：</h4><ul><li>转交给<strong>Loader</strong>（增添boot引导是为了不让loader硬编码）。</li></ul><h4 id="loader引导加载程序">3、Loader引导加载程序</h4><ul><li>检测硬件信息。</li><li>将当前的实模式转变成<strong>保护模式</strong>（32位）或者<strong>IA-32e</strong>（64位）模式。</li><li>实模式下，内存只有1MB，即2^2020个bit表示地址空间（用两个寄存器CS：IP，因为有20根地址线），在保护模式下有4GB的内存空间，就可以将内核启动参数输入到内核启动程序。</li></ul><h4 id="内核头程序">4、内核头程序：</h4><ul><li>对GDT（全局段描述）表，IDT（中断描述）表和页表初始化，为中断处理，内存管理的初始化做准备。</li></ul><h4 id="内核初始化">5、内核初始化</h4><ul><li>首先创建0号进程，对<strong>中断处理</strong>初始化，因为要考虑到可能会有任何异常情况都导致中断。</li><li>接着是<strong>内存</strong>和<strong>进程管理</strong>的初始化，主要涉及如何获取内存信息，进行内存分配，进程控制结构PCB和进程调度。</li><li><strong>文件系统</strong>初始化，创建一个<strong>虚拟文件系统</strong>，有一个挂载目录。解决文件到磁盘逻辑地址映射，磁盘逻辑地址映射到物理地址映射。</li><li>创建1号进程，第一个用户进程，进入到用户态，完成完整的用户文件系统创建过程，就可以访问根文件系统中的init程序做一些用户态初始化。</li><li>创建2号进程，是内核进程的祖先，负责管理调度其它内核进程。</li></ul><h4id="内核态有了调度进程之后用户便可以开始创建自己的进程启动完成">6、内核态有了调度进程之后，用户便可以开始创建自己的进程，启动完成。</h4>]]></content>
    
    
    <categories>
      
      <category>计算机基础</category>
      
      <category>操作系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/07/31/hello-world/"/>
    <url>/2022/07/31/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your veryfirst post. Check <a href="https://hexo.io/docs/">documentation</a> formore info. If you get any problems when using Hexo, you can find theanswer in <ahref="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> oryou can ask me on <ahref="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
